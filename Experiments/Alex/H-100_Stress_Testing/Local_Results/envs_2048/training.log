[INFO] Using python from: C:\miniconda3\envs\isaaclab311\python.exe
[INFO][AppLauncher]: Using device: cuda:0
[INFO][AppLauncher]: Loading experience file: C:\IsaacLab\apps\isaaclab.python.headless.kit
Loading user config located at: 'c:/miniconda3/envs/isaaclab311/lib/site-packages/isaacsim/kit/data/Kit/Isaac-Sim/5.1/user.config.json'
[Info] [carb] Logging to file: c:/miniconda3/envs/isaaclab311/lib/site-packages/isaacsim/kit/logs/Kit/Isaac-Sim/5.1/kit_20260212_224539.log
2026-02-13T03:45:39Z [12ms] [Warning] [omni.ext.plugin] [ext: extensions] Extensions config 'extension.toml' doesn't exist 'c:/isaaclab/source/extensions' or 'c:/isaaclab/source/extensions/config'
2026-02-13T03:45:39Z [242ms] [Warning] [omni.usd_config.extension] Enable omni.materialx.libs extension to use MaterialX
2026-02-13T03:45:40Z [998ms] [Warning] [carb] Acquiring non optional plugin interface which is not listed as dependency: [omni::physx::IPhysxBenchmarks v1.0] (plugin: <default plugin>), by client: omni.physics.physx.plugin. Add it to CARB_PLUGIN_IMPL_DEPS() macro of a client.
2026-02-13T03:45:40Z [1,016ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.
2026-02-13T03:45:45Z [5,856ms] [Warning] [gpu.foundation.plugin] Skipping unsupported non-NVIDIA GPU: Intel(R) Graphics
2026-02-13T03:45:45Z [5,856ms] [Warning] [gpu.foundation.plugin] Skipping unsupported non-NVIDIA GPU: Intel(R) Graphics

|---------------------------------------------------------------------------------------------|
| Driver Version: 573.44        | Graphics API: D3D12
|=============================================================================================|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|     |                                  |        |     |            | Bus-ID    |            |
|---------------------------------------------------------------------------------------------|
| 0   | NVIDIA RTX 2000 Ada Generation.. | Yes: 0 |     | 7960    MB | 10de      | de0e0100.. |
|     |                                  |        |     |            | 28b8      | 0          |
|     |                                  |        |     |            | 1         |            |
|---------------------------------------------------------------------------------------------|
| 1   | Intel(R) Graphics                |        |     | 128     MB | 8086      | 7c0a0100.. |
|     |                                  |        |     |            | 7dd5      | 0          |
|     |                                  |        |     |            | N/A       |            |
|=============================================================================================|
| OS: Windows 11 Pro, Version: 10.0 (25H2), Build: 26200, Kernel: 10.0.26100.7623
| Processor: Intel(R) Core(TM) Ultra 9 185H
| Cores: 16 | Logical Cores: 22
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 32212 | Free Memory: 15282
| Total Page/Swap (MB): 58836 | Free Page/Swap: 29053
|---------------------------------------------------------------------------------------------|
2026-02-13T03:45:45Z [6,309ms] [Warning] [gpu.foundation.plugin] PCIe link generation current (3) and maximum (4) for device 0 don't match.
[INFO]: Parsing configuration from: isaaclab_tasks.manager_based.locomotion.velocity.config.anymal_c.rough_env_cfg:AnymalCRoughEnvCfg
[INFO]: Parsing configuration from: isaaclab_tasks.manager_based.locomotion.velocity.config.anymal_c.agents.rsl_rl_ppo_cfg:AnymalCRoughPPORunnerCfg
[INFO] Logging experiment in directory: C:\IsaacLab\logs\rsl_rl\anymal_c_rough
Exact experiment name requested from command line: 2026-02-12_22-45-49

[36m======================================================================================================================[0m
[36m[1m[INFO][IsaacLab]: Logging to file: C:\Users\GABRIE~1\AppData\Local\Temp\isaaclab\logs\isaaclab_2026-02-12_22-45-49.log[0m
[36m======================================================================================================================[0m

[33m22:45:49 [simulation_context.py] WARNING: The `enable_external_forces_every_iteration` parameter in the PhysxCfg is set to False. If you are experiencing noisy velocities, consider enabling this flag. You may need to slightly increase the number of velocity iterations (setting it to 1 or 2 rather than 0), together with this flag, to improve the accuracy of velocity updates.[0m
[INFO]: Base environment:
	Environment device    : cuda:0
	Environment seed      : 42
	Physics step-size     : 0.005
	Rendering step-size   : 0.02
	Environment step-size : 0.02
[INFO] Generating terrains based on curriculum took : 1.666656 seconds
[INFO]: Time taken for scene creation : 5.436508 seconds
[INFO]: Scene manager:  <class InteractiveScene>
	Number of environments: 2048
	Environment spacing   : 2.5
	Source prim name      : /World/envs/env_0
	Global prim paths     : ['/World/ground']
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
[INFO]: Time taken for simulation start : 4.012552 seconds
[INFO] Command Manager:  <CommandManager> contains 1 active terms.
+------------------------------------------------+
|              Active Command Terms              |
+-------+---------------+------------------------+
| Index | Name          |          Type          |
+-------+---------------+------------------------+
|   0   | base_velocity | UniformVelocityCommand |
+-------+---------------+------------------------+

[INFO] Event Manager:  <EventManager> contains 3 active terms.
+--------------------------------------+
| Active Event Terms in Mode: 'startup' |
+----------+---------------------------+
|  Index   | Name                      |
+----------+---------------------------+
|    0     | physics_material          |
|    1     | add_base_mass             |
|    2     | base_com                  |
+----------+---------------------------+
+---------------------------------------+
|  Active Event Terms in Mode: 'reset'  |
+--------+------------------------------+
| Index  | Name                         |
+--------+------------------------------+
|   0    | base_external_force_torque   |
|   1    | reset_base                   |
|   2    | reset_robot_joints           |
+--------+------------------------------+
+----------------------------------------------+
|    Active Event Terms in Mode: 'interval'    |
+-------+------------+-------------------------+
| Index | Name       | Interval time range (s) |
+-------+------------+-------------------------+
|   0   | push_robot |       (10.0, 15.0)      |
+-------+------------+-------------------------+

[INFO] Recorder Manager:  <RecorderManager> contains 0 active terms.
+---------------------+
| Active Recorder Terms |
+-----------+---------+
|   Index   | Name    |
+-----------+---------+
+-----------+---------+

[INFO] Action Manager:  <ActionManager> contains 1 active terms.
+------------------------------------+
|  Active Action Terms (shape: 12)   |
+--------+-------------+-------------+
| Index  | Name        |   Dimension |
+--------+-------------+-------------+
|   0    | joint_pos   |          12 |
+--------+-------------+-------------+

[INFO] Observation Manager: <ObservationManager> contains 1 groups.
+----------------------------------------------------------+
| Active Observation Terms in Group: 'policy' (shape: (235,)) |
+-----------+--------------------------------+-------------+
|   Index   | Name                           |    Shape    |
+-----------+--------------------------------+-------------+
|     0     | base_lin_vel                   |     (3,)    |
|     1     | base_ang_vel                   |     (3,)    |
|     2     | projected_gravity              |     (3,)    |
|     3     | velocity_commands              |     (3,)    |
|     4     | joint_pos                      |    (12,)    |
|     5     | joint_vel                      |    (12,)    |
|     6     | actions                        |    (12,)    |
|     7     | height_scan                    |    (187,)   |
+-----------+--------------------------------+-------------+

[INFO] Termination Manager:  <TerminationManager> contains 2 active terms.
+---------------------------------+
|     Active Termination Terms    |
+-------+--------------+----------+
| Index | Name         | Time Out |
+-------+--------------+----------+
|   0   | time_out     |   True   |
|   1   | base_contact |  False   |
+-------+--------------+----------+

[INFO] Reward Manager:  <RewardManager> contains 11 active terms.
+-----------------------------------------+
|           Active Reward Terms           |
+-------+----------------------+----------+
| Index | Name                 |   Weight |
+-------+----------------------+----------+
|   0   | track_lin_vel_xy_exp |      1.0 |
|   1   | track_ang_vel_z_exp  |      0.5 |
|   2   | lin_vel_z_l2         |     -2.0 |
|   3   | ang_vel_xy_l2        |    -0.05 |
|   4   | dof_torques_l2       |   -1e-05 |
|   5   | dof_acc_l2           | -2.5e-07 |
|   6   | action_rate_l2       |    -0.01 |
|   7   | feet_air_time        |    0.125 |
|   8   | undesired_contacts   |     -1.0 |
|   9   | flat_orientation_l2  |      0.0 |
|   10  | dof_pos_limits       |      0.0 |
+-------+----------------------+----------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 1 active terms.
+---------------------------+
|  Active Curriculum Terms  |
+--------+------------------+
| Index  | Name             |
+--------+------------------+
|   0    | terrain_levels   |
+--------+------------------+

[INFO]: Completed setting up the environment...
C:\miniconda3\envs\isaaclab311\Lib\site-packages\torch\nn\modules\module.py:1762: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\cudnn\RNN.cpp:1481.)
  return forward_call(*args, **kwargs)
2026-02-13T03:45:59Z [20,253ms] [Warning] [omni.physx.fabric.plugin] FabricManager::initializePointInstancer mismatched prototypes on point instancer: /Visuals/Command/velocity_goal.
2026-02-13T03:45:59Z [20,253ms] [Warning] [omni.physx.fabric.plugin] FabricManager::initializePointInstancer mismatched prototypes on point instancer: /Visuals/Command/velocity_current.
C:\miniconda3\envs\isaaclab311\Lib\site-packages\rsl_rl\utils\utils.py:244: UserWarning: The observation configuration dictionary 'obs_groups' must contain the 'policy' key. As an observation group with the name 'policy' was found, this is assumed to be the observation set. Consider adding the 'policy' key to the 'obs_groups' dictionary for clarity. This behavior will be removed in a future version.
  warnings.warn(
C:\miniconda3\envs\isaaclab311\Lib\site-packages\rsl_rl\utils\utils.py:290: UserWarning: The observation configuration dictionary 'obs_groups' must contain the 'critic' key. As the configuration for 'critic' is missing, the observations from the 'policy' set are used. Consider adding the 'critic' key to the 'obs_groups' dictionary for clarity. This behavior will be removed in a future version.
  warnings.warn(
--------------------------------------------------------------------------------
Resolved observation sets: 
	 policy :  ['policy']
	 critic :  ['policy']
--------------------------------------------------------------------------------
ActorCritic.__init__ got unexpected arguments, which will be ignored: ['state_dependent_std']
Actor MLP: MLP(
  (0): Linear(in_features=235, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=12, bias=True)
)
Critic MLP: MLP(
  (0): Linear(in_features=235, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
C:\miniconda3\envs\isaaclab311\Lib\site-packages\torch\nn\modules\module.py:1762: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\cudnn\RNN.cpp:1481.)
  return forward_call(*args, **kwargs)
################################################################################
                       [1m Learning iteration 0/10 [0m                        

                       Computation: 9366 steps/s (collection: 4.944s, learning 0.304s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0508
               Mean surrogate loss: 0.0135
                 Mean entropy loss: 17.0057
                       Mean reward: -0.52
               Mean episode length: 13.62
Episode_Reward/track_lin_vel_xy_exp: 0.0014
Episode_Reward/track_ang_vel_z_exp: 0.0018
       Episode_Reward/lin_vel_z_l2: -0.0098
      Episode_Reward/ang_vel_xy_l2: -0.0027
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0093
     Episode_Reward/action_rate_l2: -0.0028
      Episode_Reward/feet_air_time: -0.0004
 Episode_Reward/undesired_contacts: -0.0003
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4953
Metrics/base_velocity/error_vel_xy: 0.0216
Metrics/base_velocity/error_vel_yaw: 0.0180
      Episode_Termination/time_out: 0.0128
  Episode_Termination/base_contact: 0.0001
--------------------------------------------------------------------------------
                   Total timesteps: 49152
                    Iteration time: 5.25s
                      Time elapsed: 00:00:05
                               ETA: 00:00:52

Could not find git repository in C:\miniconda3\envs\isaaclab311\Lib\site-packages\rsl_rl\__init__.py. Skipping.
Storing git diff for 'IsaacLab' in: C:\IsaacLab\logs\rsl_rl\anymal_c_rough\2026-02-12_22-45-49\git\IsaacLab.diff
################################################################################
                       [1m Learning iteration 1/10 [0m                        

                       Computation: 11860 steps/s (collection: 3.947s, learning 0.197s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0270
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 16.9872
                       Mean reward: -1.08
               Mean episode length: 33.85
Episode_Reward/track_lin_vel_xy_exp: 0.0059
Episode_Reward/track_ang_vel_z_exp: 0.0059
       Episode_Reward/lin_vel_z_l2: -0.0183
      Episode_Reward/ang_vel_xy_l2: -0.0098
     Episode_Reward/dof_torques_l2: -0.0048
         Episode_Reward/dof_acc_l2: -0.0206
     Episode_Reward/action_rate_l2: -0.0087
      Episode_Reward/feet_air_time: -0.0010
 Episode_Reward/undesired_contacts: -0.0049
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4623
Metrics/base_velocity/error_vel_xy: 0.0623
Metrics/base_velocity/error_vel_yaw: 0.0546
      Episode_Termination/time_out: 0.0380
  Episode_Termination/base_contact: 0.0085
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 4.14s
                      Time elapsed: 00:00:09
                               ETA: 00:00:42

################################################################################
                       [1m Learning iteration 2/10 [0m                        

                       Computation: 10912 steps/s (collection: 4.286s, learning 0.218s)
             Mean action noise std: 0.98
          Mean value_function loss: 0.0208
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 16.8776
                       Mean reward: -1.61
               Mean episode length: 58.36
Episode_Reward/track_lin_vel_xy_exp: 0.0109
Episode_Reward/track_ang_vel_z_exp: 0.0095
       Episode_Reward/lin_vel_z_l2: -0.0198
      Episode_Reward/ang_vel_xy_l2: -0.0152
     Episode_Reward/dof_torques_l2: -0.0082
         Episode_Reward/dof_acc_l2: -0.0302
     Episode_Reward/action_rate_l2: -0.0144
      Episode_Reward/feet_air_time: -0.0015
 Episode_Reward/undesired_contacts: -0.0116
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4194
Metrics/base_velocity/error_vel_xy: 0.1012
Metrics/base_velocity/error_vel_yaw: 0.0963
      Episode_Termination/time_out: 0.0603
  Episode_Termination/base_contact: 0.0294
--------------------------------------------------------------------------------
                   Total timesteps: 147456
                    Iteration time: 4.50s
                      Time elapsed: 00:00:13
                               ETA: 00:00:37

################################################################################
                       [1m Learning iteration 3/10 [0m                        

                       Computation: 10498 steps/s (collection: 4.412s, learning 0.270s)
             Mean action noise std: 0.97
          Mean value_function loss: 0.0164
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 16.6796
                       Mean reward: -2.07
               Mean episode length: 76.92
Episode_Reward/track_lin_vel_xy_exp: 0.0165
Episode_Reward/track_ang_vel_z_exp: 0.0120
       Episode_Reward/lin_vel_z_l2: -0.0234
      Episode_Reward/ang_vel_xy_l2: -0.0211
     Episode_Reward/dof_torques_l2: -0.0112
         Episode_Reward/dof_acc_l2: -0.0386
     Episode_Reward/action_rate_l2: -0.0195
      Episode_Reward/feet_air_time: -0.0021
 Episode_Reward/undesired_contacts: -0.0277
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3775
Metrics/base_velocity/error_vel_xy: 0.1321
Metrics/base_velocity/error_vel_yaw: 0.1299
      Episode_Termination/time_out: 0.0833
  Episode_Termination/base_contact: 0.0480
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 4.68s
                      Time elapsed: 00:00:18
                               ETA: 00:00:32

################################################################################
                       [1m Learning iteration 4/10 [0m                        

                       Computation: 10500 steps/s (collection: 4.472s, learning 0.209s)
             Mean action noise std: 0.95
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 16.5269
                       Mean reward: -2.43
               Mean episode length: 93.78
Episode_Reward/track_lin_vel_xy_exp: 0.0172
Episode_Reward/track_ang_vel_z_exp: 0.0155
       Episode_Reward/lin_vel_z_l2: -0.0245
      Episode_Reward/ang_vel_xy_l2: -0.0263
     Episode_Reward/dof_torques_l2: -0.0142
         Episode_Reward/dof_acc_l2: -0.0466
     Episode_Reward/action_rate_l2: -0.0245
      Episode_Reward/feet_air_time: -0.0027
 Episode_Reward/undesired_contacts: -0.0257
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3456
Metrics/base_velocity/error_vel_xy: 0.1755
Metrics/base_velocity/error_vel_yaw: 0.1681
      Episode_Termination/time_out: 0.0972
  Episode_Termination/base_contact: 0.0638
--------------------------------------------------------------------------------
                   Total timesteps: 245760
                    Iteration time: 4.68s
                      Time elapsed: 00:00:23
                               ETA: 00:00:27

################################################################################
                       [1m Learning iteration 5/10 [0m                        

                       Computation: 10612 steps/s (collection: 4.424s, learning 0.208s)
             Mean action noise std: 0.94
          Mean value_function loss: 0.0100
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 16.3469
                       Mean reward: -2.94
               Mean episode length: 120.42
Episode_Reward/track_lin_vel_xy_exp: 0.0286
Episode_Reward/track_ang_vel_z_exp: 0.0193
       Episode_Reward/lin_vel_z_l2: -0.0252
      Episode_Reward/ang_vel_xy_l2: -0.0269
     Episode_Reward/dof_torques_l2: -0.0188
         Episode_Reward/dof_acc_l2: -0.0514
     Episode_Reward/action_rate_l2: -0.0311
      Episode_Reward/feet_air_time: -0.0032
 Episode_Reward/undesired_contacts: -0.0425
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3191
Metrics/base_velocity/error_vel_xy: 0.2001
Metrics/base_velocity/error_vel_yaw: 0.2091
      Episode_Termination/time_out: 0.1147
  Episode_Termination/base_contact: 0.0724
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 4.63s
                      Time elapsed: 00:00:27
                               ETA: 00:00:23

################################################################################
                       [1m Learning iteration 6/10 [0m                        

                       Computation: 10751 steps/s (collection: 4.363s, learning 0.209s)
             Mean action noise std: 0.92
          Mean value_function loss: 0.0101
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 16.1467
                       Mean reward: -3.19
               Mean episode length: 141.60
Episode_Reward/track_lin_vel_xy_exp: 0.0267
Episode_Reward/track_ang_vel_z_exp: 0.0217
       Episode_Reward/lin_vel_z_l2: -0.0270
      Episode_Reward/ang_vel_xy_l2: -0.0294
     Episode_Reward/dof_torques_l2: -0.0204
         Episode_Reward/dof_acc_l2: -0.0557
     Episode_Reward/action_rate_l2: -0.0343
      Episode_Reward/feet_air_time: -0.0036
 Episode_Reward/undesired_contacts: -0.0474
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2918
Metrics/base_velocity/error_vel_xy: 0.2432
Metrics/base_velocity/error_vel_yaw: 0.2332
      Episode_Termination/time_out: 0.1351
  Episode_Termination/base_contact: 0.0791
--------------------------------------------------------------------------------
                   Total timesteps: 344064
                    Iteration time: 4.57s
                      Time elapsed: 00:00:32
                               ETA: 00:00:18

################################################################################
                       [1m Learning iteration 7/10 [0m                        

                       Computation: 10828 steps/s (collection: 4.325s, learning 0.214s)
             Mean action noise std: 0.91
          Mean value_function loss: 0.0080
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 15.9685
                       Mean reward: -3.40
               Mean episode length: 159.78
Episode_Reward/track_lin_vel_xy_exp: 0.0378
Episode_Reward/track_ang_vel_z_exp: 0.0264
       Episode_Reward/lin_vel_z_l2: -0.0280
      Episode_Reward/ang_vel_xy_l2: -0.0331
     Episode_Reward/dof_torques_l2: -0.0230
         Episode_Reward/dof_acc_l2: -0.0579
     Episode_Reward/action_rate_l2: -0.0376
      Episode_Reward/feet_air_time: -0.0035
 Episode_Reward/undesired_contacts: -0.0493
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2641
Metrics/base_velocity/error_vel_xy: 0.2484
Metrics/base_velocity/error_vel_yaw: 0.2458
      Episode_Termination/time_out: 0.1523
  Episode_Termination/base_contact: 0.0868
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 4.54s
                      Time elapsed: 00:00:37
                               ETA: 00:00:13

################################################################################
                       [1m Learning iteration 8/10 [0m                        

                       Computation: 10381 steps/s (collection: 4.511s, learning 0.224s)
             Mean action noise std: 0.89
          Mean value_function loss: 0.0067
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 15.7335
                       Mean reward: -3.70
               Mean episode length: 184.49
Episode_Reward/track_lin_vel_xy_exp: 0.0455
Episode_Reward/track_ang_vel_z_exp: 0.0291
       Episode_Reward/lin_vel_z_l2: -0.0298
      Episode_Reward/ang_vel_xy_l2: -0.0387
     Episode_Reward/dof_torques_l2: -0.0272
         Episode_Reward/dof_acc_l2: -0.0680
     Episode_Reward/action_rate_l2: -0.0444
      Episode_Reward/feet_air_time: -0.0045
 Episode_Reward/undesired_contacts: -0.0581
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2359
Metrics/base_velocity/error_vel_xy: 0.2859
Metrics/base_velocity/error_vel_yaw: 0.3090
      Episode_Termination/time_out: 0.1700
  Episode_Termination/base_contact: 0.0952
--------------------------------------------------------------------------------
                   Total timesteps: 442368
                    Iteration time: 4.73s
                      Time elapsed: 00:00:41
                               ETA: 00:00:09

################################################################################
                       [1m Learning iteration 9/10 [0m                        

                       Computation: 10036 steps/s (collection: 4.680s, learning 0.217s)
             Mean action noise std: 0.88
          Mean value_function loss: 0.0058
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 15.5786
                       Mean reward: -3.87
               Mean episode length: 205.87
Episode_Reward/track_lin_vel_xy_exp: 0.0548
Episode_Reward/track_ang_vel_z_exp: 0.0339
       Episode_Reward/lin_vel_z_l2: -0.0295
      Episode_Reward/ang_vel_xy_l2: -0.0397
     Episode_Reward/dof_torques_l2: -0.0291
         Episode_Reward/dof_acc_l2: -0.0693
     Episode_Reward/action_rate_l2: -0.0468
      Episode_Reward/feet_air_time: -0.0048
 Episode_Reward/undesired_contacts: -0.0546
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2090
Metrics/base_velocity/error_vel_xy: 0.3042
Metrics/base_velocity/error_vel_yaw: 0.3134
      Episode_Termination/time_out: 0.1890
  Episode_Termination/base_contact: 0.1020
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 4.90s
                      Time elapsed: 00:00:46
                               ETA: 00:00:04

Training time: 48.14 seconds
