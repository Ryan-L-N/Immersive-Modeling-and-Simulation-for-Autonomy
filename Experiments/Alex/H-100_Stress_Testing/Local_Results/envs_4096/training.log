[INFO] Using python from: C:\miniconda3\envs\isaaclab311\python.exe
[INFO][AppLauncher]: Using device: cuda:0
[INFO][AppLauncher]: Loading experience file: C:\IsaacLab\apps\isaaclab.python.headless.kit
Loading user config located at: 'c:/miniconda3/envs/isaaclab311/lib/site-packages/isaacsim/kit/data/Kit/Isaac-Sim/5.1/user.config.json'
[Info] [carb] Logging to file: c:/miniconda3/envs/isaaclab311/lib/site-packages/isaacsim/kit/logs/Kit/Isaac-Sim/5.1/kit_20260212_224659.log
2026-02-13T03:46:59Z [12ms] [Warning] [omni.ext.plugin] [ext: extensions] Extensions config 'extension.toml' doesn't exist 'c:/isaaclab/source/extensions' or 'c:/isaaclab/source/extensions/config'
2026-02-13T03:47:00Z [316ms] [Warning] [omni.usd_config.extension] Enable omni.materialx.libs extension to use MaterialX
2026-02-13T03:47:00Z [1,092ms] [Warning] [carb] Acquiring non optional plugin interface which is not listed as dependency: [omni::physx::IPhysxBenchmarks v1.0] (plugin: <default plugin>), by client: omni.physics.physx.plugin. Add it to CARB_PLUGIN_IMPL_DEPS() macro of a client.
2026-02-13T03:47:00Z [1,115ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.
2026-02-13T03:47:07Z [7,521ms] [Warning] [gpu.foundation.plugin] Skipping unsupported non-NVIDIA GPU: Intel(R) Graphics
2026-02-13T03:47:07Z [7,522ms] [Warning] [gpu.foundation.plugin] Skipping unsupported non-NVIDIA GPU: Intel(R) Graphics

|---------------------------------------------------------------------------------------------|
| Driver Version: 573.44        | Graphics API: D3D12
|=============================================================================================|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|     |                                  |        |     |            | Bus-ID    |            |
|---------------------------------------------------------------------------------------------|
| 0   | NVIDIA RTX 2000 Ada Generation.. | Yes: 0 |     | 7960    MB | 10de      | de0e0100.. |
|     |                                  |        |     |            | 28b8      | 0          |
|     |                                  |        |     |            | 1         |            |
|---------------------------------------------------------------------------------------------|
| 1   | Intel(R) Graphics                |        |     | 128     MB | 8086      | 7c0a0100.. |
|     |                                  |        |     |            | 7dd5      | 0          |
|     |                                  |        |     |            | N/A       |            |
|=============================================================================================|
| OS: Windows 11 Pro, Version: 10.0 (25H2), Build: 26200, Kernel: 10.0.26100.7623
| Processor: Intel(R) Core(TM) Ultra 9 185H
| Cores: 16 | Logical Cores: 22
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 32212 | Free Memory: 15269
| Total Page/Swap (MB): 58836 | Free Page/Swap: 29044
|---------------------------------------------------------------------------------------------|
2026-02-13T03:47:07Z [8,033ms] [Warning] [gpu.foundation.plugin] PCIe link generation current (3) and maximum (4) for device 0 don't match.
[INFO]: Parsing configuration from: isaaclab_tasks.manager_based.locomotion.velocity.config.anymal_c.rough_env_cfg:AnymalCRoughEnvCfg
[INFO]: Parsing configuration from: isaaclab_tasks.manager_based.locomotion.velocity.config.anymal_c.agents.rsl_rl_ppo_cfg:AnymalCRoughPPORunnerCfg
[INFO] Logging experiment in directory: C:\IsaacLab\logs\rsl_rl\anymal_c_rough
Exact experiment name requested from command line: 2026-02-12_22-47-11

[36m======================================================================================================================[0m
[36m[1m[INFO][IsaacLab]: Logging to file: C:\Users\GABRIE~1\AppData\Local\Temp\isaaclab\logs\isaaclab_2026-02-12_22-47-11.log[0m
[36m======================================================================================================================[0m

[33m22:47:11 [simulation_context.py] WARNING: The `enable_external_forces_every_iteration` parameter in the PhysxCfg is set to False. If you are experiencing noisy velocities, consider enabling this flag. You may need to slightly increase the number of velocity iterations (setting it to 1 or 2 rather than 0), together with this flag, to improve the accuracy of velocity updates.[0m
[INFO]: Base environment:
	Environment device    : cuda:0
	Environment seed      : 42
	Physics step-size     : 0.005
	Rendering step-size   : 0.02
	Environment step-size : 0.02
[INFO] Generating terrains based on curriculum took : 2.009197 seconds
[INFO]: Time taken for scene creation : 9.608075 seconds
[INFO]: Scene manager:  <class InteractiveScene>
	Number of environments: 4096
	Environment spacing   : 2.5
	Source prim name      : /World/envs/env_0
	Global prim paths     : ['/World/ground']
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
[INFO]: Time taken for simulation start : 7.286506 seconds
[INFO] Command Manager:  <CommandManager> contains 1 active terms.
+------------------------------------------------+
|              Active Command Terms              |
+-------+---------------+------------------------+
| Index | Name          |          Type          |
+-------+---------------+------------------------+
|   0   | base_velocity | UniformVelocityCommand |
+-------+---------------+------------------------+

[INFO] Event Manager:  <EventManager> contains 3 active terms.
+--------------------------------------+
| Active Event Terms in Mode: 'startup' |
+----------+---------------------------+
|  Index   | Name                      |
+----------+---------------------------+
|    0     | physics_material          |
|    1     | add_base_mass             |
|    2     | base_com                  |
+----------+---------------------------+
+---------------------------------------+
|  Active Event Terms in Mode: 'reset'  |
+--------+------------------------------+
| Index  | Name                         |
+--------+------------------------------+
|   0    | base_external_force_torque   |
|   1    | reset_base                   |
|   2    | reset_robot_joints           |
+--------+------------------------------+
+----------------------------------------------+
|    Active Event Terms in Mode: 'interval'    |
+-------+------------+-------------------------+
| Index | Name       | Interval time range (s) |
+-------+------------+-------------------------+
|   0   | push_robot |       (10.0, 15.0)      |
+-------+------------+-------------------------+

[INFO] Recorder Manager:  <RecorderManager> contains 0 active terms.
+---------------------+
| Active Recorder Terms |
+-----------+---------+
|   Index   | Name    |
+-----------+---------+
+-----------+---------+

[INFO] Action Manager:  <ActionManager> contains 1 active terms.
+------------------------------------+
|  Active Action Terms (shape: 12)   |
+--------+-------------+-------------+
| Index  | Name        |   Dimension |
+--------+-------------+-------------+
|   0    | joint_pos   |          12 |
+--------+-------------+-------------+

[INFO] Observation Manager: <ObservationManager> contains 1 groups.
+----------------------------------------------------------+
| Active Observation Terms in Group: 'policy' (shape: (235,)) |
+-----------+--------------------------------+-------------+
|   Index   | Name                           |    Shape    |
+-----------+--------------------------------+-------------+
|     0     | base_lin_vel                   |     (3,)    |
|     1     | base_ang_vel                   |     (3,)    |
|     2     | projected_gravity              |     (3,)    |
|     3     | velocity_commands              |     (3,)    |
|     4     | joint_pos                      |    (12,)    |
|     5     | joint_vel                      |    (12,)    |
|     6     | actions                        |    (12,)    |
|     7     | height_scan                    |    (187,)   |
+-----------+--------------------------------+-------------+

[INFO] Termination Manager:  <TerminationManager> contains 2 active terms.
+---------------------------------+
|     Active Termination Terms    |
+-------+--------------+----------+
| Index | Name         | Time Out |
+-------+--------------+----------+
|   0   | time_out     |   True   |
|   1   | base_contact |  False   |
+-------+--------------+----------+

[INFO] Reward Manager:  <RewardManager> contains 11 active terms.
+-----------------------------------------+
|           Active Reward Terms           |
+-------+----------------------+----------+
| Index | Name                 |   Weight |
+-------+----------------------+----------+
|   0   | track_lin_vel_xy_exp |      1.0 |
|   1   | track_ang_vel_z_exp  |      0.5 |
|   2   | lin_vel_z_l2         |     -2.0 |
|   3   | ang_vel_xy_l2        |    -0.05 |
|   4   | dof_torques_l2       |   -1e-05 |
|   5   | dof_acc_l2           | -2.5e-07 |
|   6   | action_rate_l2       |    -0.01 |
|   7   | feet_air_time        |    0.125 |
|   8   | undesired_contacts   |     -1.0 |
|   9   | flat_orientation_l2  |      0.0 |
|   10  | dof_pos_limits       |      0.0 |
+-------+----------------------+----------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 1 active terms.
+---------------------------+
|  Active Curriculum Terms  |
+--------+------------------+
| Index  | Name             |
+--------+------------------+
|   0    | terrain_levels   |
+--------+------------------+

[INFO]: Completed setting up the environment...
C:\miniconda3\envs\isaaclab311\Lib\site-packages\torch\nn\modules\module.py:1762: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\cudnn\RNN.cpp:1481.)
  return forward_call(*args, **kwargs)
2026-02-13T03:47:29Z [29,868ms] [Warning] [omni.physx.fabric.plugin] FabricManager::initializePointInstancer mismatched prototypes on point instancer: /Visuals/Command/velocity_goal.
2026-02-13T03:47:29Z [29,868ms] [Warning] [omni.physx.fabric.plugin] FabricManager::initializePointInstancer mismatched prototypes on point instancer: /Visuals/Command/velocity_current.
C:\miniconda3\envs\isaaclab311\Lib\site-packages\rsl_rl\utils\utils.py:244: UserWarning: The observation configuration dictionary 'obs_groups' must contain the 'policy' key. As an observation group with the name 'policy' was found, this is assumed to be the observation set. Consider adding the 'policy' key to the 'obs_groups' dictionary for clarity. This behavior will be removed in a future version.
  warnings.warn(
C:\miniconda3\envs\isaaclab311\Lib\site-packages\rsl_rl\utils\utils.py:290: UserWarning: The observation configuration dictionary 'obs_groups' must contain the 'critic' key. As the configuration for 'critic' is missing, the observations from the 'policy' set are used. Consider adding the 'critic' key to the 'obs_groups' dictionary for clarity. This behavior will be removed in a future version.
  warnings.warn(
--------------------------------------------------------------------------------
Resolved observation sets: 
	 policy :  ['policy']
	 critic :  ['policy']
--------------------------------------------------------------------------------
ActorCritic.__init__ got unexpected arguments, which will be ignored: ['state_dependent_std']
Actor MLP: MLP(
  (0): Linear(in_features=235, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=12, bias=True)
)
Critic MLP: MLP(
  (0): Linear(in_features=235, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
C:\miniconda3\envs\isaaclab311\Lib\site-packages\torch\nn\modules\module.py:1762: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\cudnn\RNN.cpp:1481.)
  return forward_call(*args, **kwargs)
################################################################################
                       [1m Learning iteration 0/10 [0m                        

                       Computation: 11103 steps/s (collection: 8.274s, learning 0.579s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0723
               Mean surrogate loss: 0.0077
                 Mean entropy loss: 17.0015
                       Mean reward: -0.66
               Mean episode length: 15.31
Episode_Reward/track_lin_vel_xy_exp: 0.0027
Episode_Reward/track_ang_vel_z_exp: 0.0020
       Episode_Reward/lin_vel_z_l2: -0.0134
      Episode_Reward/ang_vel_xy_l2: -0.0030
     Episode_Reward/dof_torques_l2: -0.0014
         Episode_Reward/dof_acc_l2: -0.0096
     Episode_Reward/action_rate_l2: -0.0030
      Episode_Reward/feet_air_time: -0.0003
 Episode_Reward/undesired_contacts: -0.0008
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.5264
Metrics/base_velocity/error_vel_xy: 0.0188
Metrics/base_velocity/error_vel_yaw: 0.0175
      Episode_Termination/time_out: 0.0124
  Episode_Termination/base_contact: 0.0003
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 8.85s
                      Time elapsed: 00:00:08
                               ETA: 00:01:28

Could not find git repository in C:\miniconda3\envs\isaaclab311\Lib\site-packages\rsl_rl\__init__.py. Skipping.
Storing git diff for 'IsaacLab' in: C:\IsaacLab\logs\rsl_rl\anymal_c_rough\2026-02-12_22-47-11\git\IsaacLab.diff
################################################################################
                       [1m Learning iteration 1/10 [0m                        

                       Computation: 12051 steps/s (collection: 7.754s, learning 0.403s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0345
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 16.9742
                       Mean reward: -1.35
               Mean episode length: 39.94
Episode_Reward/track_lin_vel_xy_exp: 0.0067
Episode_Reward/track_ang_vel_z_exp: 0.0058
       Episode_Reward/lin_vel_z_l2: -0.0232
      Episode_Reward/ang_vel_xy_l2: -0.0095
     Episode_Reward/dof_torques_l2: -0.0049
         Episode_Reward/dof_acc_l2: -0.0210
     Episode_Reward/action_rate_l2: -0.0087
      Episode_Reward/feet_air_time: -0.0009
 Episode_Reward/undesired_contacts: -0.0083
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4928
Metrics/base_velocity/error_vel_xy: 0.0607
Metrics/base_velocity/error_vel_yaw: 0.0563
      Episode_Termination/time_out: 0.0371
  Episode_Termination/base_contact: 0.0096
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 8.16s
                      Time elapsed: 00:00:17
                               ETA: 00:01:16

################################################################################
                       [1m Learning iteration 2/10 [0m                        

                       Computation: 11455 steps/s (collection: 8.183s, learning 0.398s)
             Mean action noise std: 0.98
          Mean value_function loss: 0.0258
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 16.8468
                       Mean reward: -1.90
               Mean episode length: 63.99
Episode_Reward/track_lin_vel_xy_exp: 0.0114
Episode_Reward/track_ang_vel_z_exp: 0.0095
       Episode_Reward/lin_vel_z_l2: -0.0225
      Episode_Reward/ang_vel_xy_l2: -0.0153
     Episode_Reward/dof_torques_l2: -0.0079
         Episode_Reward/dof_acc_l2: -0.0291
     Episode_Reward/action_rate_l2: -0.0140
      Episode_Reward/feet_air_time: -0.0015
 Episode_Reward/undesired_contacts: -0.0197
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4567
Metrics/base_velocity/error_vel_xy: 0.0973
Metrics/base_velocity/error_vel_yaw: 0.0903
      Episode_Termination/time_out: 0.0606
  Episode_Termination/base_contact: 0.0219
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 8.58s
                      Time elapsed: 00:00:25
                               ETA: 00:01:08

################################################################################
                       [1m Learning iteration 3/10 [0m                        

                       Computation: 11034 steps/s (collection: 8.499s, learning 0.410s)
             Mean action noise std: 0.97
          Mean value_function loss: 0.0203
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 16.6680
                       Mean reward: -2.51
               Mean episode length: 83.93
Episode_Reward/track_lin_vel_xy_exp: 0.0157
Episode_Reward/track_ang_vel_z_exp: 0.0128
       Episode_Reward/lin_vel_z_l2: -0.0269
      Episode_Reward/ang_vel_xy_l2: -0.0195
     Episode_Reward/dof_torques_l2: -0.0112
         Episode_Reward/dof_acc_l2: -0.0354
     Episode_Reward/action_rate_l2: -0.0195
      Episode_Reward/feet_air_time: -0.0021
 Episode_Reward/undesired_contacts: -0.0360
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.4196
Metrics/base_velocity/error_vel_xy: 0.1309
Metrics/base_velocity/error_vel_yaw: 0.1267
      Episode_Termination/time_out: 0.0868
  Episode_Termination/base_contact: 0.0317
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 8.91s
                      Time elapsed: 00:00:34
                               ETA: 00:01:00

################################################################################
                       [1m Learning iteration 4/10 [0m                        

                       Computation: 10862 steps/s (collection: 8.625s, learning 0.425s)
             Mean action noise std: 0.95
          Mean value_function loss: 0.0159
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 16.5287
                       Mean reward: -2.98
               Mean episode length: 107.27
Episode_Reward/track_lin_vel_xy_exp: 0.0204
Episode_Reward/track_ang_vel_z_exp: 0.0160
       Episode_Reward/lin_vel_z_l2: -0.0278
      Episode_Reward/ang_vel_xy_l2: -0.0230
     Episode_Reward/dof_torques_l2: -0.0145
         Episode_Reward/dof_acc_l2: -0.0423
     Episode_Reward/action_rate_l2: -0.0251
      Episode_Reward/feet_air_time: -0.0029
 Episode_Reward/undesired_contacts: -0.0462
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3905
Metrics/base_velocity/error_vel_xy: 0.1725
Metrics/base_velocity/error_vel_yaw: 0.1679
      Episode_Termination/time_out: 0.1098
  Episode_Termination/base_contact: 0.0374
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 9.05s
                      Time elapsed: 00:00:43
                               ETA: 00:00:52

################################################################################
                       [1m Learning iteration 5/10 [0m                        

                       Computation: 11090 steps/s (collection: 8.475s, learning 0.389s)
             Mean action noise std: 0.94
          Mean value_function loss: 0.0138
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 16.3517
                       Mean reward: -3.31
               Mean episode length: 129.42
Episode_Reward/track_lin_vel_xy_exp: 0.0258
Episode_Reward/track_ang_vel_z_exp: 0.0191
       Episode_Reward/lin_vel_z_l2: -0.0289
      Episode_Reward/ang_vel_xy_l2: -0.0277
     Episode_Reward/dof_torques_l2: -0.0176
         Episode_Reward/dof_acc_l2: -0.0470
     Episode_Reward/action_rate_l2: -0.0298
      Episode_Reward/feet_air_time: -0.0033
 Episode_Reward/undesired_contacts: -0.0535
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3611
Metrics/base_velocity/error_vel_xy: 0.2098
Metrics/base_velocity/error_vel_yaw: 0.2056
      Episode_Termination/time_out: 0.1325
  Episode_Termination/base_contact: 0.0432
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 8.86s
                      Time elapsed: 00:00:52
                               ETA: 00:00:43

################################################################################
                       [1m Learning iteration 6/10 [0m                        

                       Computation: 11729 steps/s (collection: 7.959s, learning 0.422s)
             Mean action noise std: 0.93
          Mean value_function loss: 0.0118
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 16.1863
                       Mean reward: -3.68
               Mean episode length: 151.27
Episode_Reward/track_lin_vel_xy_exp: 0.0302
Episode_Reward/track_ang_vel_z_exp: 0.0230
       Episode_Reward/lin_vel_z_l2: -0.0289
      Episode_Reward/ang_vel_xy_l2: -0.0310
     Episode_Reward/dof_torques_l2: -0.0208
         Episode_Reward/dof_acc_l2: -0.0524
     Episode_Reward/action_rate_l2: -0.0346
      Episode_Reward/feet_air_time: -0.0036
 Episode_Reward/undesired_contacts: -0.0663
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3330
Metrics/base_velocity/error_vel_xy: 0.2360
Metrics/base_velocity/error_vel_yaw: 0.2324
      Episode_Termination/time_out: 0.1530
  Episode_Termination/base_contact: 0.0495
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 8.38s
                      Time elapsed: 00:01:00
                               ETA: 00:00:34

################################################################################
                       [1m Learning iteration 7/10 [0m                        

                       Computation: 12750 steps/s (collection: 7.344s, learning 0.365s)
             Mean action noise std: 0.91
          Mean value_function loss: 0.0096
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 15.9902
                       Mean reward: -4.27
               Mean episode length: 179.03
Episode_Reward/track_lin_vel_xy_exp: 0.0342
Episode_Reward/track_ang_vel_z_exp: 0.0271
       Episode_Reward/lin_vel_z_l2: -0.0298
      Episode_Reward/ang_vel_xy_l2: -0.0345
     Episode_Reward/dof_torques_l2: -0.0245
         Episode_Reward/dof_acc_l2: -0.0613
     Episode_Reward/action_rate_l2: -0.0404
      Episode_Reward/feet_air_time: -0.0042
 Episode_Reward/undesired_contacts: -0.0776
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.3077
Metrics/base_velocity/error_vel_xy: 0.2852
Metrics/base_velocity/error_vel_yaw: 0.2717
      Episode_Termination/time_out: 0.1734
  Episode_Termination/base_contact: 0.0547
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 7.71s
                      Time elapsed: 00:01:08
                               ETA: 00:00:25

################################################################################
                       [1m Learning iteration 8/10 [0m                        

                       Computation: 12950 steps/s (collection: 7.222s, learning 0.369s)
             Mean action noise std: 0.91
          Mean value_function loss: 0.0080
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 15.8296
                       Mean reward: -4.45
               Mean episode length: 192.61
Episode_Reward/track_lin_vel_xy_exp: 0.0434
Episode_Reward/track_ang_vel_z_exp: 0.0300
       Episode_Reward/lin_vel_z_l2: -0.0312
      Episode_Reward/ang_vel_xy_l2: -0.0382
     Episode_Reward/dof_torques_l2: -0.0260
         Episode_Reward/dof_acc_l2: -0.0652
     Episode_Reward/action_rate_l2: -0.0424
      Episode_Reward/feet_air_time: -0.0043
 Episode_Reward/undesired_contacts: -0.0772
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2811
Metrics/base_velocity/error_vel_xy: 0.2874
Metrics/base_velocity/error_vel_yaw: 0.2911
      Episode_Termination/time_out: 0.1923
  Episode_Termination/base_contact: 0.0612
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 7.59s
                      Time elapsed: 00:01:16
                               ETA: 00:00:16

################################################################################
                       [1m Learning iteration 9/10 [0m                        

                       Computation: 13239 steps/s (collection: 7.049s, learning 0.376s)
             Mean action noise std: 0.89
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 15.6904
                       Mean reward: -4.77
               Mean episode length: 212.63
Episode_Reward/track_lin_vel_xy_exp: 0.0310
Episode_Reward/track_ang_vel_z_exp: 0.0348
       Episode_Reward/lin_vel_z_l2: -0.0331
      Episode_Reward/ang_vel_xy_l2: -0.0423
     Episode_Reward/dof_torques_l2: -0.0298
         Episode_Reward/dof_acc_l2: -0.0666
     Episode_Reward/action_rate_l2: -0.0476
      Episode_Reward/feet_air_time: -0.0051
 Episode_Reward/undesired_contacts: -0.0800
Episode_Reward/flat_orientation_l2: 0.0000
     Episode_Reward/dof_pos_limits: 0.0000
         Curriculum/terrain_levels: 3.2538
Metrics/base_velocity/error_vel_xy: 0.3653
Metrics/base_velocity/error_vel_yaw: 0.3206
      Episode_Termination/time_out: 0.2114
  Episode_Termination/base_contact: 0.0673
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 7.43s
                      Time elapsed: 00:01:23
                               ETA: 00:00:08

Training time: 85.11 seconds
